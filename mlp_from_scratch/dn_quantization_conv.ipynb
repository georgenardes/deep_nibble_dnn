{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train mlp on MNIST using fp32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from dataset import load_mnist\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "# load dataset\n",
    "x_train, y_train, x_test, y_test = load_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_in = keras.layers.Input((28,28,1))\n",
    "\n",
    "x = keras.layers.Conv2D(16, kernel_size=3, padding=\"SAME\")(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.MaxPool2D()(x)\n",
    "x = keras.layers.Conv2D(32, kernel_size=3, padding=\"SAME\")(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.MaxPool2D()(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(256)(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Dense(256)(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.Dense(10)(x)\n",
    "\n",
    "lenet = keras.Model(inputs=[x_in], outputs=[x])\n",
    "lenet.summary()\n",
    "lenet.compile(optimizer=keras.optimizers.Adam(0.001), loss=keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.02), metrics=[\"accuracy\"])\n",
    "hist = lenet.fit(x_train, y_train, 256, 10, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NeuralNetwork import QNeuralNetworkWithScale, QLeNet\n",
    "import Activations\n",
    "import FullyConnectedLayer \n",
    "\n",
    "\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "# Create and train the neural network\n",
    "qlenet = QLeNet(input_shape=input_shape, output_size=y_train.shape[-1], batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# como vincular um modelo com o outro?\n",
    "# mais vale criar um modelo do 0 com base no modelo q vier...\n",
    "# o problema maior é criar cada camada\n",
    "# a rede é só um array de camadas\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import quantizer\n",
    "\n",
    "from ConvLayer import *\n",
    "\n",
    "dn_layers = []\n",
    "for l in lenet.layers:\n",
    "    if isinstance(l, keras.layers.Conv2D):    \n",
    "        print(\"instanciating conv layer...\")\n",
    "        l.weights[0].shape[0],l.weights[0].shape[1]\n",
    "\n",
    "        w_shape = l.weights[0].shape\n",
    "        nfilters = w_shape[3]\n",
    "        kernel_size = w_shape[0]\n",
    "        input_channels = w_shape[2]\n",
    "        strides=[1,1,1,1] ### TODO: variable strides\n",
    "        padding= l.padding\n",
    "\n",
    "        # create QCONVLAYER\n",
    "        qfc = QConvLayer(nfilters, kernel_size, input_channels, strides, padding)\n",
    "        \n",
    "        fpw = l.weights[0].numpy()        \n",
    "        fpb  = l.weights[1].numpy()\n",
    "        \n",
    "        w_scale = np.max(np.abs(fpw))\n",
    "        \n",
    "        fpw_scaled = fpw / w_scale\n",
    "        qw = quantizer.quantize(fpw_scaled, True, False)\n",
    "        \n",
    "        # atribui o peso quantizado\n",
    "        qfc.qw = qw\n",
    "        qfc.weights_scale = fpw_scaled\n",
    "               \n",
    "\n",
    "        plt.hist(np.ravel(qw), bins=64)\n",
    "        plt.hist(np.ravel(fpw_scaled), bins=64)\n",
    "        plt.hist(np.ravel(fpw), bins=64)\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        fpb_scaled = fpb / w_scale\n",
    "        qb = quantizer.quantize(fpb_scaled, True, False)\n",
    "        qfc.qb = qb\n",
    "        plt.hist(np.ravel(qb), bins=64)\n",
    "        plt.hist(np.ravel(fpb_scaled), bins=64)\n",
    "        plt.hist(np.ravel(fpb), bins=64)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        dn_layers.append(qfc)\n",
    "\n",
    "    if isinstance(l, keras.layers.MaxPool2D):    \n",
    "        print(l)\n",
    "        dn_maxpool = CustomMaxPool(l.pool_size, l.strides)\n",
    "        dn_layers.append(dn_maxpool)\n",
    "\n",
    "    if isinstance(l, keras.layers.Flatten):    \n",
    "        dn_layers.append(CustomFlatten(l.input_shape))\n",
    "    if isinstance(l, keras.layers.Dense):        \n",
    "        \n",
    "        qfc = FullyConnectedLayer.QFullyConnectedLayerWithScale(l.weights[0].shape[0],l.weights[0].shape[1])\n",
    "        \n",
    "        fpw = l.weights[0].numpy()        \n",
    "        fpb  = l.weights[1].numpy()\n",
    "        \n",
    "        w_scale = np.max(np.abs(fpw))\n",
    "        \n",
    "        fpw_scaled = fpw / w_scale\n",
    "        qw = quantizer.quantize(fpw_scaled, True, False)\n",
    "        \n",
    "        # atribui o peso quantizado\n",
    "        qfc.qw = qw\n",
    "        qfc.weights_scale = fpw_scaled\n",
    "               \n",
    "\n",
    "        plt.hist(np.ravel(qw), bins=64)\n",
    "        plt.hist(np.ravel(fpw_scaled), bins=64)\n",
    "        plt.hist(np.ravel(fpw), bins=64)\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        fpb_scaled = fpb / w_scale\n",
    "        qb = quantizer.quantize(fpb_scaled, True, False)\n",
    "        qfc.qb = qb\n",
    "        plt.hist(np.ravel(qb), bins=64)\n",
    "        plt.hist(np.ravel(fpb_scaled), bins=64)\n",
    "        plt.hist(np.ravel(fpb), bins=64)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        dn_layers.append(qfc)\n",
    "\n",
    "\n",
    "    if isinstance(l, keras.layers.ReLU):                \n",
    "        dn_layers.append(Activations.QReLU())\n",
    "\n",
    "print(dn_layers)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qlenet.load_layers_from_model(lenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = qlenet.predict(x_test, 256)\n",
    "print(y_pred.shape)\n",
    "# Calculate accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(y_pred == tf.argmax(y_test, axis=1), tf.float32))\n",
    "print(f\"Accuracy: {accuracy * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetune the dnn\n",
    "qlenet.train(x_train, y_train, learning_rate=0.000010, num_epochs=1, x_val=x_test, y_val=y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
